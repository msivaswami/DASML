{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Data Imputation\n",
    "\n",
    "Welcome to the \"Handling Missing Data\" practical session.  \n",
    "\n",
    "Programming Language : Python \n",
    "Editor : Jupyter Notebook. \n",
    "\n",
    "\n",
    "Pandas : Data loading, processing, transformation and manipulation.\n",
    "Scikit-learn : Example data source, ML and statistical analysis\n",
    "\n",
    "\n",
    "This example illustrates how to apply different preprocessing and feature\n",
    "imputation pipelines to different subsets of features, using\n",
    "SimpleImputer, KNNImputer. This is particularly handy for the\n",
    "case of datasets that contain heterogeneous data types, since we may want to\n",
    "impute the numeric as well as categorical features\n",
    "\n",
    "\n",
    "In this example, the numeric data is standard-scaled after mean-imputation,\n",
    "while the categorical data is one-hot encoded after imputing missing values\n",
    "with a new category (``'missing'``).\n",
    "\n",
    "In addition, we show two different ways to dispatch the columns to the\n",
    "particular pre-processor: by column names and by column data types.\n",
    "\n",
    "Finally you'll be tasked with apply new transformeation on a new data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      age  sex   cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "0    63.0  1.0  4.0      10.0  60.0  2.0      1.0     12.0    3.0     11.0   \n",
      "1    44.0  1.0  4.0       3.0   NaN  2.0      1.0      8.0    NaN     14.0   \n",
      "2    60.0  1.0  4.0       5.0  27.0  2.0      1.0     19.0    3.0      6.0   \n",
      "3    55.0  1.0  4.0      11.0  39.0  2.0      1.0     25.0    3.0     10.0   \n",
      "4    66.0  1.0  3.0      33.0  22.0  3.0      2.0     53.0    3.0      5.0   \n",
      "..    ...  ...  ...       ...   ...  ...      ...      ...    ...      ...   \n",
      "195  54.0  0.0  4.0      41.0  95.0  3.0      1.0      NaN    NaN     14.0   \n",
      "196  62.0  1.0  1.0       1.0  30.0  2.0      1.0      1.0    1.0      1.0   \n",
      "197  55.0  1.0  4.0      37.0  33.0  3.0      1.0      4.0    2.0      NaN   \n",
      "198  58.0  1.0  NaN       1.0   3.0  NaN      NaN      1.0    1.0      1.0   \n",
      "199  62.0  1.0  2.0      34.0   NaN  2.0      NaN     47.0    3.0     14.0   \n",
      "\n",
      "     slope   ca  thal  diagnosis of heart disease  \n",
      "0      3.0  1.0   1.0                           3  \n",
      "1      1.0  NaN   1.0                           1  \n",
      "2      4.0  1.0   NaN                           3  \n",
      "3      2.0  1.0   1.0                           2  \n",
      "4      3.0  1.0   1.0                           1  \n",
      "..     ...  ...   ...                         ...  \n",
      "195    1.0  1.0   1.0                           2  \n",
      "196    1.0  1.0   1.0                           1  \n",
      "197    1.0  NaN   3.0                           3  \n",
      "198    1.0  1.0   1.0                           1  \n",
      "199    1.0  1.0   NaN                           2  \n",
      "\n",
      "[200 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# Author:  Mamun Rashid <m.rrashid.1@gmail.com>\n",
    "\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "## Load the LongIsland_Heart_Data Set\n",
    "heart_df = pd.read_csv('LongIsland_Heart_Data.csv')\n",
    "\n",
    "heart_df.describe()\n",
    "print(heart_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>diagnosis of heart disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>62.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "69   63.0  1.0  2.0       1.0  26.0  3.0      1.0      NaN    1.0      NaN   \n",
       "120  62.0  1.0  3.0       1.0   NaN  NaN      1.0      1.0    NaN      NaN   \n",
       "130   NaN  NaN  3.0       NaN  29.0  3.0      1.0      NaN    NaN      NaN   \n",
       "156  64.0  1.0  NaN      15.0   7.0  2.0      1.0      NaN    3.0      NaN   \n",
       "175  58.0  1.0  4.0       NaN  22.0  2.0      1.0     55.0    NaN     14.0   \n",
       "186  61.0  NaN  3.0       NaN   NaN  2.0      0.0     51.0    3.0     14.0   \n",
       "\n",
       "     slope   ca  thal  diagnosis of heart disease  \n",
       "69     NaN  1.0   NaN                           2  \n",
       "120    1.0  1.0   1.0                           3  \n",
       "130    1.0  1.0   3.0                           2  \n",
       "156    3.0  NaN   1.0                           3  \n",
       "175    NaN  NaN   1.0                           1  \n",
       "186    1.0  1.0   NaN                           4  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 3: Check for missing data\n",
    "\n",
    "# Description: This cell is to check if there is any missing data in the DataFrame.\n",
    "\n",
    "\n",
    "heart_df.loc[ heart_df.isnull().sum(axis=1) >= 4,  :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>diagnosis of heart disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0  63.0  1.0  4.0      10.0  60.0  2.0      1.0     12.0    3.0     11.0   \n",
       "1  44.0  1.0  4.0       3.0   NaN  2.0      1.0      8.0    NaN     14.0   \n",
       "2  60.0  1.0  4.0       5.0  27.0  2.0      1.0     19.0    3.0      6.0   \n",
       "3  55.0  1.0  4.0      11.0  39.0  2.0      1.0     25.0    3.0     10.0   \n",
       "4  66.0  1.0  3.0      33.0  22.0  3.0      2.0     53.0    3.0      5.0   \n",
       "\n",
       "   slope   ca  thal  diagnosis of heart disease  \n",
       "0    3.0  1.0   1.0                           3  \n",
       "1    1.0  NaN   1.0                           1  \n",
       "2    4.0  1.0   NaN                           3  \n",
       "3    2.0  1.0   1.0                           2  \n",
       "4    3.0  1.0   1.0                           1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data have the following useful features, used to test basic ML prototypes.\n",
    "\n",
    " Numeric Features:\n",
    "\n",
    " * ``chol``: float;\n",
    " -- serum cholestoral in mg/dl\n",
    " * ``thalach``: float.\n",
    " -- maximum heart rate achieved\n",
    "\n",
    " \n",
    " Categorical Features:\n",
    "\n",
    " * ``sex``: categories encoded as numeric ``{'1 = male', '2=female'}``;\n",
    " * ``cp``: ordinal integers ``{1, 2, 3, 4}``.\n",
    "        -- Value 1: typical angina\n",
    "        -- Value 2: atypical angina\n",
    "        -- Value 3: non-anginal pain\n",
    "        -- Value 4: asymptomatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chol</th>\n",
       "      <th>thalach</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chol  thalach  sex   cp\n",
       "0  60.0     12.0  1.0  4.0\n",
       "1   NaN      8.0  1.0  4.0\n",
       "2  27.0     19.0  1.0  4.0\n",
       "3  39.0     25.0  1.0  4.0\n",
       "4  22.0     53.0  1.0  3.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reduced = heart_df.loc[:, ['chol', 'thalach','sex','cp']]\n",
    "X_reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's going on here? Can we break this down?\n",
    "\n",
    "# 1. We describe features as numeric or categorical\n",
    "\n",
    "## We separate the numeric features\n",
    "## For categorical variables we will use a simple imputer to replace the missing values with median of the remaining values\"\n",
    "numeric_features = ['chol', 'thalach']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median'))])\n",
    "\n",
    "## We separate the categorical features\n",
    "## For categorical variables we will use a simple imputer with a constant = \"missing\"\n",
    "categorical_features = ['sex','cp']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=-1))])\n",
    "\n",
    "\n",
    "## We combine both \"categorical\" and \"numerical\" imputer in a preprocessor. \n",
    "## We use a column transformer to apply the transformation.\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numerical_imputer', numeric_transformer, numeric_features),\n",
    "        ('categorical_imputer', categorical_transformer, categorical_features)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     chol  thalach  sex   cp\n",
      "0    60.0     12.0  1.0  4.0\n",
      "1     NaN      8.0  1.0  4.0\n",
      "2    27.0     19.0  1.0  4.0\n",
      "3    39.0     25.0  1.0  4.0\n",
      "4    22.0     53.0  1.0  3.0\n",
      "..    ...      ...  ...  ...\n",
      "195  95.0      NaN  0.0  4.0\n",
      "196  30.0      1.0  1.0  1.0\n",
      "197  33.0      4.0  1.0  4.0\n",
      "198   3.0      1.0  1.0  NaN\n",
      "199   NaN     47.0  1.0  2.0\n",
      "\n",
      "[200 rows x 4 columns]\n",
      "     chol thalach  sex   cp\n",
      "0    60.0    12.0  1.0  4.0\n",
      "1    29.0     8.0  1.0  4.0\n",
      "2    27.0    19.0  1.0  4.0\n",
      "3    39.0    25.0  1.0  4.0\n",
      "4    22.0    53.0  1.0  3.0\n",
      "..    ...     ...  ...  ...\n",
      "195  95.0    19.0  0.0  4.0\n",
      "196  30.0     1.0  1.0  1.0\n",
      "197  33.0     4.0  1.0  4.0\n",
      "198   3.0     1.0  1.0 -1.0\n",
      "199  29.0    47.0  1.0  2.0\n",
      "\n",
      "[200 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "## Apply the pre-processor pipeline on the reduced data frame. \n",
    "\n",
    "print(X_reduced)\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "new_X_reduced = clf.fit_transform(X_reduced)\n",
    "\n",
    "new_X_reduced_df = pd.DataFrame( new_X_reduced )\n",
    "new_X_reduced_df.columns = [ numeric_features + categorical_features ]\n",
    "\n",
    "print(new_X_reduced_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your Task\n",
    "1. What other types of imputations options are available in SimpleImputer ?\n",
    "   Hint : Look at the SimpleImputer Documentation at scikit-learn\n",
    "\n",
    "2. Instead of \"median\" use \"mean\" to impute values for the following two numeric features. \n",
    "    - oldpeak\n",
    "    - trestbps\n",
    "\n",
    "    2.1 What is the average value of 'oldpeak' before and after imputation. \n",
    "\n",
    "\n",
    "3. Instead of \"constant\" use \"most_frequent\" to impute values for the following two catetorical features. \n",
    "    - ca             [ ca : number of major vessels (0-3) colored by flourosopy ]\n",
    "    - restecg           : resting electrocardiographic results\n",
    "                            -- Value 0: normal\n",
    "                            -- Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n",
    "                            -- Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Your Task\n",
    "# 1.1 What other types of imputations options are available  ?\n",
    "#    Hint : Look at the SimpleImputer Documentation at scikit-learn\n",
    "\n",
    "## Answer\n",
    "    # impute.IterativeImputer([estimator, ...]) : Multivariate imputer that estimates each feature from all the others.\n",
    "    # impute.KNNImputer(*[, missing_values, ...])  : Imputation for completing missing values using k-Nearest Neighbors.\n",
    "\n",
    "\n",
    "# 1.2 What other types of imputations options are available in SimpleImputer ?\n",
    "#    Hint : Look at the SimpleImputer Documentation at scikit-learn\n",
    "\n",
    "\n",
    "## Answer : \n",
    "# If “mean”, then replace missing values using the mean along each column. Can only be used with numeric data.\n",
    "# If “median”, then replace missing values using the median along each column. Can only be used with numeric data.\n",
    "# If “most_frequent”, then replace missing using the most frequent value along each column. Can be used with strings or numeric data. If there is more than one such value, only the smallest is returned.\n",
    "# If “constant”, then replace missing values with fill_value. Can be used with strings or numeric data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Instead of \"median\" use \"mean\" to impute values for the following two numeric features. \n",
    "#     - oldpeak\n",
    "#     - trestbps\n",
    "\n",
    "\n",
    "# 3. Instead of \"constant\" use \"most_frequent\" to impute values for the following two catetorical features. \n",
    "#     - ca             [ ca : number of major vessels (0-3) colored by flourosopy ]\n",
    "#     - restecg           : resting electrocardiographic results\n",
    "#                             -- Value 0: normal\n",
    "#                             -- Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n",
    "#                             -- Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n",
    "\n",
    "\n",
    "# 4. What is the average value of 'oldpeak' before and after imputation ?\n",
    "\n",
    "\n",
    "\n",
    "# 1. We describe features as numeric or categorical\n",
    "\n",
    "## ----------- Complete ------------ ## \n",
    "# numeric_features = [' ... ', '... ']\n",
    "# numeric_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy=' ... '))])\n",
    "\n",
    "# categorical_features = ['...','...']\n",
    "# categorical_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='...'))])\n",
    "\n",
    "\n",
    "## We combine both \"categorical\" and \"numerical\" imputer in a preprocessor. \n",
    "## We use a column transformer to apply the transformation.\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "## Apply the pre-processor pipeline on the reduced data frame. \n",
    "\n",
    "X_reduced = heart_df.loc[:, numeric_features + categorical_features ]\n",
    "\n",
    "print( \" Old Mean : \" +  str( X_reduced['oldpeak'].mean() ) )\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "new_X_reduced = clf.fit_transform(X_reduced)\n",
    "\n",
    "new_X_reduced_df = pd.DataFrame( new_X_reduced )\n",
    "new_X_reduced_df.columns = [ numeric_features + categorical_features ]\n",
    "\n",
    "print( \" New Mean : \" +  str( new_X_reduced_df['oldpeak'].mean() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Instead of \"SimpleImputer\" use Use KNN Imputer for the following two numeric features. \n",
    "   - oldpeak     \n",
    "   - trestbps\n",
    "\n",
    "### 6. What is the average value of 'oldpeak' before and after imputation ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Instead of \"SimpleImputer\" use Use KNN Imputer for the following two numeric features. \n",
    "#     - oldpeak\n",
    "#     - trestbps\n",
    "\n",
    "# 6. What is the average value of 'oldpeak' before and after imputation ?\n",
    "\n",
    "\n",
    "## ----------- Complete ------------ ##\n",
    "# numeric_features = ['...', '...']\n",
    "# numeric_transformer = Pipeline(steps=[\n",
    "#     ('imputer', KNNImputer( ... ))])\n",
    "\n",
    "\n",
    "## We separate the categorical features\n",
    "## For categorical variables we will use a simple imputer with a constant = \"missing\"\n",
    "categorical_features = ['ca','restecg']\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent', fill_value=-1))])\n",
    "\n",
    "\n",
    "## We combine both \"categorical\" and \"numerical\" imputer in a preprocessor. \n",
    "## We use a column transformer to apply the transformation.\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "## Apply the pre-processor pipeline on the reduced data frame. \n",
    "\n",
    "X_reduced = heart_df.loc[:, numeric_features + categorical_features ]\n",
    "\n",
    "print( \" Old Mean : \" +  str( X_reduced['oldpeak'].mean() ) )\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "new_X_reduced = clf.fit_transform(X_reduced)\n",
    "\n",
    "new_X_reduced_df = pd.DataFrame( new_X_reduced )\n",
    "new_X_reduced_df.columns = [ numeric_features + categorical_features ]\n",
    "\n",
    "print( \" New Mean : \" +  str( new_X_reduced_df['oldpeak'].mean() ) )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "27504229a786ecc4bac7f6801848e44cb1a63648e4d666cbb9fdea5e9f215e02"
  },
  "kernelspec": {
   "display_name": "Python 3.8 [python/3.8]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
